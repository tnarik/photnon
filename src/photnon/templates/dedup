#!/usr/bin/env python3
import argparse

import json
import codecs
import os
import filecmp
from collections import Counter

EXIT_CODE_RUN_WITH_F = 1

parser = argparse.ArgumentParser(description="Photon", prefix_chars="-+")
parser.add_argument('-n', '--dry-run',
    action='store_true',
	help='do not change files (do not remove or create)',
	dest='dry_run')
parser.add_argument('-v', '--verbose',
    action='store_true',
	help='verbose output',
	dest='verbose')
parser.add_argument('-f', '--force',
    action='store_true',
	help='run regardless of machine not-matching',
	dest='force')
args = parser.parse_args()


if not args.force and os.uname()[1] != "{{ script_hostname }}":
	print("Running from machine '{}' instead of '{{ script_hostname }}' (where the files were read)".format(os.uname()[1]))
	print("If you are sure you want to do this (file layout might be different, so it's risky), please run with:")
	print("    -f")
	exit(EXIT_CODE_RUN_WITH_F)

# For every digest-based group, generate merged JSON metadata:
#	Tags: are joined without duplications, as a sorted list.
#	Description: do they match? If there is a single one, use that one
#	AltDescriptions: In case there is more than one not-matching description
#   Title: Use from the JSON or the alternative filenames.
#.  AltTitles: In case there is more than one not-matching title

{%- for i, group in digest_groups %}
tags = set()
descriptions = []
altdescriptions = []
titles = []
alttitles = []
paths = []
has_jsons = []
{% set ns = namespace(main_file='', main_file_path='') -%}
{% for j, e in group.iterrows() -%}
{% if e['has_json'] -%}
with codecs.open( "{{ e['fullpath'] }}.json", 'r','utf-8-sig') as f:
	js = json.load(f)
	tags.update( js['Tags'] if isinstance(js['Tags'], list)
		 else js['Tags'].split(' ') )
	descriptions.append(js['Description'])
	if 'AltDescriptions' in js: altdescriptions.extend(js['AltDescriptions'])
	titles.append(js['Title'])
	if 'AltTitles' in js: alttitles.extend(js['AltTitles'])
	{% if e['persist_version'] != KEPT_MARK -%}
	paths.append("{{ e['fullpath'] }}")
	has_jsons.append(True)
	{% else -%}
	{% set ns.main_file = e['name'] -%}
	{% set ns.main_file_path = e['fullpath'] -%}
	{% endif %}
{% else -%}
{% if e['persist_version'] != KEPT_MARK -%}
titles.append("{{ e['name'] }}")
paths.append("{{ e['fullpath'] }}")
has_jsons.append(False)
{% else -%}
{% set ns.main_file = e['name'] -%}
{% set ns.main_file_path = e['fullpath'] -%}
{% endif -%}
{% endif -%}
{% endfor -%}

metadata = {'Tags': sorted(list(tags)),
			'Description': '',
			'Title': '' }

descriptions = Counter(descriptions)
del descriptions['']
if (len(descriptions) >= 1):
	metadata['Description'] = descriptions.most_common(1)[0][0]

metadata['AltDescriptions'] = sorted(set(altdescriptions + [d[0] for d in descriptions.most_common()[1:]]))
if len(metadata['AltDescriptions']) == 0:
	del metadata['AltDescriptions']

titles = Counter(titles)
del titles['']
if len(titles) >= 1:
	metadata['Title'] = titles.most_common(1)[0][0]

metadata['AltTitles'] = sorted(set(alttitles + [t[0] for t in titles.most_common()[1:]]))
if len(metadata['AltTitles']) == 0:
	del metadata['AltTitles']

if ( ( len(metadata['Tags']) > 0 or metadata['Description'] != '' or metadata['Title'] != '' ) and
	 ( ('AltTitles' not in metadata or len(metadata['AltTitles']) > 0) and
	   ('AltDescriptions' not in metadata or len(metadata['AltDescriptions']) > 0) ) ):
	if args.dry_run:
		print("touch {{ ns.main_file_path }}.json", "" if not args.verbose else " = "+json.dumps(metadata))
	else:
		with open("{{ ns.main_file_path }}.json", 'w') as f:
			json.dump(metadata, f)

for p,h in zip(paths, has_jsons):
	if filecmp.cmp('{{ ns.main_file_path }}', p, shallow=False):
		if args.dry_run:
			print("rm \"{}\"".format(p))
			if h: print("rm \"{}.json\"".format(p))
		else:
			os.remove("{}".format(p))
			if h: os.remove("{}.json".format(p))

{% endfor %}

if args.verbose: print('{{digest_groups|length}} digests processed')
{#print("{} / {} = {} files in total".format(count, count_nj, count_t))#}